---
title: "OBER_proj2_BODAC_seasonality"
author: "Pieter van Veelen"
date: "5/12/2022"
output: html_document
---

### Background

This is repository contains the analysis of microbial communities comprising biofilms in Biological Oxygen-Dosed Activated Carbon. The dataset describes the temporal dynamics of microbial communities in roughly bimonthly collected samples of BODAC and backwash water in an UltraPureWater factory in Emmen.
Water purification performance of two consecutively placed BODAC filters demonstrates a remarkable system performance stability of 12 years, without replacement of activated carbon. Regular backwashing of the filters is responsible for prevention of saturation, while subsequent regeneration of microbial biofilms with hypothesized stable composition facilitates remarkable efficiency in water purification without downstream reverse osmosis membrane fouling in the system. Here we investigated the seasonal regeneration and allegedly stable biofilm community composition in BODAC filters and backwash water.
Input data were created by sequencing 16S rRNA gene amplicons using primers 515F and 926R on Illumina Miseq (300 bp PE). Fastq sequence files were analysed using QIIME2 (scripts can be found in the scripts/QIIME2/ directory) and the feature table, taxonomic assignments, phylogeny and metadata were imported into R (in input_data/). The [SILVA database v.138](https://www.arb-silva.de/documentation/release-138/) was used as reference data for taxonomic assignments. This analysis was published by [**Bernadet et al. (2022)**](url DOI): *Regular backwashing promotes stable regeneration of microbial biofilms on activated carbon in BODAC filters*.

**The full RMarkdown document is available as RMD file in this repository**
<br>
```{r , eval=TRUE, echo=FALSE, include=FALSE, message=FALSE, warning=FALSE}

# set optional parameters
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE, 
                      message = FALSE)
options(scipen = 999, digits = 3)
```

```{r install packages, eval=TRUE, echo=FALSE, include=FALSE, message=FALSE, warning=FALSE}

# install packages
if (!requireNamespace("BiocManager", quietly = TRUE)){install.packages("BiocManager")}
if (!requireNamespace("devtools", quietly = TRUE)){install.packages("devtools")}
if (!requireNamespace("remotes", quietly = TRUE)){install.packages("remotes")}
if (!requireNamespace("BiocManager", quietly = TRUE)){BiocManager::install(version = "3.12")}
if (!requireNamespace("phyloseq", quietly = TRUE)){BiocManager::install("phyloseq")}
if (!requireNamespace("microbiome", quietly = TRUE)){BiocManager::install("microbiome")}
if (!requireNamespace("decontam", quietly = TRUE)){BiocManager::install("decontam")}
if (!requireNamespace("qiime2R", quietly = TRUE)){devtools::install_github("jbisanz/qiime2R")}
if (!requireNamespace("breakaway", quietly = TRUE)){remotes::install_github("adw96/breakaway")}
if (!requireNamespace("DivNet", quietly = TRUE)){remotes::install_github("adw96/DivNet")}
if (!requireNamespace("ampvis2", quietly = TRUE)){remotes::install_github("MadsAlbertsen/ampvis2")}
if (!require("DECIPHER", quietly = TRUE)) {BiocManager::install("DECIPHER", version = "3.12")}
if (!requireNamespace("ensembleTax", quietly = TRUE)){install.packages("ensembleTax")}



```

```{r library loading, message=F, echo=T, eval=T, warning=T, include=F, cache=F}

## load required packages
library(Hmisc)
library(phyloseq)
library(qiime2R)
library(tidyverse)
library(magrittr)
library(devtools)
library(qiime2R)
library(here)
library(breakaway)
library(DivNet)
library(openxlsx)
library(ape)
library(vegan)
library(ggtext)
library(cowplot)
library(RColorBrewer)
library(microbiome)
library(lme4)
library(lmerTest)
library(decontam)
library(ampvis2)
library(glue)
library(lubridate)
library(DECIPHER)
library(ensembleTax)

```

```{r project organization, message=F, echo=F, eval=T, warning=F, include=F, cache=T}

# project name
proj = "OBER_proj2_Q14878_BODAC_seasonality"

# create directories
if(!dir.exists("figures")){dir.create("figures")}
if(!dir.exists("output_data")){dir.create("output_data")} 
if(!dir.exists("scripts")){dir.create("scripts")} 
if(!dir.exists("scripts/QIIME2")){dir.create("scripts/QIIME2")} 
```

### Data import
All input data have been created with QIIME2 and are imported in {r session_info()$platform$version}. QIIME2 scripts and parameter settings are found in separate bash files that can be found in this [Github repository](https://github.com/pietervanveelen/OBER_proj2_BODAC_seasonality).<br>

```{r import data, message=F, echo=T, eval=T, warning=T, include=F, cache=F}

#creating phyloseq objects with 
physeq = qza_to_phyloseq(
  features = "input_data/OBER_16S_515F926R_Q14878_SAM1-52_table.qza",
  tree = "input_data/OBER_16S_515F926R_Q14878_SAM1-52_rooted-tree.qza",
  taxonomy = "input_data/OBER_16S_515F926R_Q14878_SAM1-52_taxonomy_NB_classifier_SILVA_132_99_16S_515F-926R_QIIME2-2019.10.qza",
    metadata = "input_data/OBER_16S_515F926R_Q14878_SAM1-52@metadata_completed_OBER_formatted.txt")

write_rds(physeq, "output_data/physeq.rds")

```


### Cleaning data set
The following quality control steps are subsequently performed to clean the data: 1) tree resolving using ape package; 2) cleaning up the metadata; 3) replacing taxonomic strings that are empty, NA, metagenome, ambiguous taxa; 4) split blanks from samples; 

```{r clean phylogeny, message=F, echo=F, eval=T, warning=T, include=F, cache=F}
### resolve phylogenetic tree ###

# evaluate tree topology
is.binary(phy_tree(physeq)) # if FALSE --> polychotomy present (node has more than 2 tips)
#TRUE

# if FALSE:
# resolve polychotomous nodes
phy_tree_resolved <- multi2di(phy_tree(physeq))
is.binary(phy_tree_resolved)
# create new phy_tree
tree2 <- phy_tree_resolved

# subset_taxa(phy_tree_resolved, Kingdom ==  "Bacteria")

# merge new phy_tree object with sample_data and otu_table into new phyloseq object
psdata_OBER <- merge_phyloseq(otu_table(physeq), sample_data(physeq), tax_table(physeq), tree2)
```

```{r clean metatdata, message=F, echo=F, eval=T, warning=F, include=F, cache=F}

# change all names to lowercase
names(sample_data(psdata_OBER)) <- tolower(names(sample_data(psdata_OBER)))

## metadata to be added
# # clean-up metadata
metadata_cleaned = 
  sample_data(psdata_OBER) %>% 
    as.data.frame() %>% 
    as_tibble() %>% 
    dplyr::mutate(across(wet_weight:purified_quantus, ~parse_number(., locale = locale(decimal_mark = ",")))) %>% 
    as.data.frame()
metadata_cleaned$sampleid = metadata_cleaned$description
metadata_cleaned = metadata_cleaned %>% select(sampleid, everything())
metadata_cleaned = sample_data(metadata_cleaned)
metadata_cleaned$sampleid = c(metadata_cleaned$sampleid[1:49], 
                              "OBER.051.blank", "OBER.052.blank", "OBER.053.blank")
sample_names(metadata_cleaned) = metadata_cleaned$sampleid

# replace formatted metadata as sample_data in psdata_OBER
sample_data(psdata_OBER) = sample_data(metadata_cleaned)


```

```{r clean taxanomy naming, message=F, echo=F, eval=T, warning=F, include=F, cache=F}

## clean taxonomy tags with no information
# specify NA taxon name tags to last known taxon names

source("scripts/tax_clean.r")
tax_clean(psdata_OBER)

```

```{r taxonomy classification of non-bacterial ASVs, message=F, echo=F, eval=F, warning=F, include=F, cache=F}
# save ASV feature IDs without phylum assignments as vector
no_phylum_ASVs = 
  psdata_OBER %>% 
  subset_taxa(is.na(Phylum)) %>% 
  psmelt() %>% 
  pull(OTU) %>% 
  unique()

View(tax_table(prune_taxa(taxa_names(psdata_OBER) %in% no_phylum_ASVs, psdata_OBER)))

# read ASV feature representative sequences as a DNAStringSet
rep_seqs = qiime2R::read_qza("input_data/OBER_16S_515F926R_Q14878_SAM1-52_representative_sequences.qza")
rep_seqs = rep_seqs$data 

# subset the representative sequences for ASVs without Phylum assignment
no_phylum_ASVs_rep_seqs = rep_seqs[no_phylum_ASVs]

# write fasta for no_phylum_ASVs
writeXStringSet(no_phylum_ASVs_rep_seqs, 'output_data/OBER_proj2_no_phylum_ASVs_rep_seqs.fasta')

### Taxonomy assignments using various reference databases
# Download from http://www2.decipher.codes/Downloads.html
# Use functions from https://search.r-project.org/CRAN/refmans/ensembleTax/html/idtax2df.html
# and https://git.wageningenur.nl/steen176/microbial/-/blob/master/vignettes/2_Taxonomic_assignment.Rmd

## SILVA 138
# load the SILVA 138 trainingset
#load("~/Wetsus_Projects/PVEE/Data_analyses/IDTAXA_DECIPHER_dbs/SILVA_SSU_r138_2019.rdata") 

#ids_SILVA <- IdTaxa(no_phylum_ASVs_rep_seqs, trainingSet, strand="both", processors=10, verbose=TRUE) 
ids_SILVA %>% idtax2df(
                    .,
                    db = "silva", # "pr2", "silva", "rdp", or "gg"
                    ranks = rank_names(psdata_OBER),
                    boot = 0,
                    rubric = NULL, # A DNAStringset can be added to link rep seqs to taxonomy information
                    return.conf = FALSE) # if TRUE the confidence scores are added, output not df
  #                  %>% 
  # filter(!is.na(family))

## RDP Ribosomal Database Project (16S)
# load the RDP v18 July 2020 trainingset
#load("~/Wetsus_Projects/PVEE/Data_analyses/IDTAXA_DECIPHER_dbs/RDP_v18-mod_July2020.rdata") 

# run IDTAXA from DECIPHER package
#ids_RDP <- IdTaxa(no_phylum_ASVs_rep_seqs, trainingSet, strand="both", processors=10, verbose=TRUE) 
ids_RDP %>% idtax2df(
                    .,
                    db = "rdp", # "pr2", "silva", "rdp", or "gg"
                    ranks = rank_names(psdata_OBER),
                    boot = 0,
                    rubric = NULL, # A DNAStringset can be added to link rep seqs to taxonomy information
                    return.conf = FALSE) # if TRUE the confidence scores are added, output not df
  #                  %>% 
  # filter(!is.na(family))

## PR2 protists rRNA database
# load the PR2 v.4 March 2021 trainingset
#load("~/Wetsus_Projects/PVEE/Data_analyses/IDTAXA_DECIPHER_dbs/PR2_v4_13_March2021.rdata") 

#ids_pr2 <- IdTaxa(no_phylum_ASVs_rep_seqs, trainingSet, strand="both", processors=10, verbose=TRUE) 
ids_pr2 %>% idtax2df(
                    .,
                    db = "rdp", # "pr2", "silva", "rdp", or "gg"
                    ranks = NULL,
                    boot = 60,
                    rubric = NULL, # A DNAStringset can be added to link rep seqs to taxonomy information
                    return.conf = FALSE) # if TRUE the confidence scores are added, output not df
  #                  %>% 
  # filter(!is.na(family))


# Convert the output object of class "Taxa" to a matrix analogous to the output from assignTaxonomy
ranks <- c("domain", "phylum", "class", "order", "family", "genus", "species") 
taxa_RDP = t(sapply(ids_RDP, function(x) {
        m <- match(ranks, x$rank)
        taxa <- x$taxon[m]
        taxa[startsWith(taxa, "unclassified_")] <- NA
        taxa
}))
taxa_SILVA = t(sapply(ids_SILVA, function(x) {
        m <- match(ranks, x$rank)
        taxa <- x$taxon[m]
        taxa[startsWith(taxa, "unclassified_")] <- NA
        taxa
}))
taxa_PR2 = t(sapply(ids_pr2, function(x) {
        m <- match(ranks, x$rank)
        taxa <- x$taxon[m]
        taxa[startsWith(taxa, "unclassified_")] <- NA
        taxa
}))
colnames(taxa_RDP) <- c(rank_names(psdata_OBER))
colnames(taxa_SILVA) <- c(rank_names(psdata_OBER))
colnames(taxa_PR2) <- c(rank_names(psdata_OBER))
as_tibble(taxa_RDP, rownames = "OTU")
taxa = bind_rows(as_tibble(taxa_RDP, rownames = "OTU") %>% 
                   dplyr::mutate(db = rep(str_extract("ids_RDP", pattern = "[^_]+$"), nrow(taxa_RDP))),
                 as_tibble(taxa_SILVA, rownames = "OTU") %>% 
                   dplyr::mutate(db = rep(str_extract("ids_SILVA", pattern = "[^_]+$"), nrow(taxa_SILVA))),
                 as_tibble(taxa_PR2, rownames = "OTU") %>% 
                   dplyr::mutate(db = rep(str_extract("ids_PR2", pattern = "[^_]+$"), nrow(taxa_PR2)))
                 )
taxa = taxa %>% select(db, OTU, everything())
taxa_resolved = taxa %>% arrange(OTU) %>% filter(!is.na(Phylum))
taxa_resolved = taxa_resolved %>% dplyr::mutate(Kingdom = if_else(is.na(Kingdom), "Eukaryota", Kingdom))

# write table for new tax_info
taxa_resolved %>% write_csv(., file = "output_data/OBER_proj2_NewTax_euk.csv")

```

```{r clean on taxonomy, message=F, echo=F, eval=F, warning=T, include=F, cache=F}

# remove non-informative taxa
old = ntaxa(psdata_OBER)
new = psdata_OBER %>% 
  subset_taxa(., Kingdom != "Eukaryota") %>% # 0 ASVs lost
  subset_taxa(., !is.na(Phylum)) %>% # 166 ASVs lost (most likely Eurkaryotes, see SI)
  subset_taxa(., Family != "Mitochondria") %>% # 986 ASVs lost
  subset_taxa(., Class != "Chloroplast") %>% # 0 ASVs lost
ntaxa()
# number of ASVs removed:
old-new # 1152 ASVs are removed

# now continue with fitered psdata_OBER:
psdata_OBER = psdata_OBER %>% 
  subset_taxa(., Kingdom != "Eukaryota") %>% # 0 ASVs lost
  subset_taxa(., !is.na(Phylum)) %>% # 166 ASVs lost (most likely Eurkaryotes, see SI)
  subset_taxa(., Family != "Mitochondria") %>% # 986 ASVs lost
  subset_taxa(., Class != "Chloroplast") # 0 ASVs lost

```


```{r filter blanks and samples, message=F, echo=F, eval=T, warning=T, include=F, cache=F}

# full dataset
psdata_OBER_blank <- subset_samples(psdata_OBER, sample_type == "blank") # subset NC blank samples
psdata_OBER_blank <- prune_taxa(taxa_sums(psdata_OBER_blank) > 0, psdata_OBER_blank) #247 taxa found in blanks
psdata_OBER <- subset_samples(psdata_OBER, sample_type != "activated_sludge" & sample_type != "blank") # subset only BODAC samples
psdata_OBER <- prune_taxa(taxa_sums(psdata_OBER) > 0, psdata_OBER) # 6119 taxa found in BODAC samples

# average and variation in coverage
mean(sample_sums(psdata_OBER)) # = 49334
summary(sample_sums(psdata_OBER))
sum(sample_sums(psdata_OBER)) # 2368027 reads after filtering BODAC samples

# number of reads in Blank (#538)
sum(sample_sums(psdata_OBER_blank)) # across 3 NCs 13565 reads were detected

```

```{r calculate relative abundance, message=F, echo=F, eval=T, warning=T, include=F, cache=F, }

# relative abundance data on BODAC samples
psdata_OBER_rel <- transform_sample_counts(psdata_OBER, fun = function(x) x/sum(x)) # 6119 taxa (100% abundance)

total_sum = sum(sample_sums(psdata_OBER)) # total reads left = 2368027

# abundance filter at (0.01%, 0.1% 0.5%)
psdata_OBER_0.01pct <- prune_taxa(taxa_sums(psdata_OBER_rel) > 0.0001, psdata_OBER)
psdata_OBER_0.05pct <- prune_taxa(taxa_sums(psdata_OBER_rel) > 0.0005, psdata_OBER)
psdata_OBER_0.1pct <- prune_taxa(taxa_sums(psdata_OBER_rel) > 0.001, psdata_OBER)

# taxa remaining after filters
ntaxa(psdata_OBER_0.01pct)  #4479 
ntaxa(psdata_OBER_0.05pct)  #2749 
ntaxa(psdata_OBER_0.1pct)   #2081 

# associated relative abundances with filters
num(100*(sum(sample_sums(psdata_OBER_0.01pct))/total_sum), digits = 3) # (99.831% abundance)
num(100*(sum(sample_sums(psdata_OBER_0.05pct))/total_sum), digits = 3) # (98.914% abundance)
num(100*(sum(sample_sums(psdata_OBER_0.1pct))/total_sum), digits = 3)  # (97.919% abundance)

### choice to continue downstream analysis with abundance filter that retains ASVs with at least 0.1% of total read abundance. (i.e. retaining > 99% of sequences)
psdata_OBER_unfiltered <- psdata_OBER # save unfiltered data
psdata_OBER <- psdata_OBER_0.01pct # overwrite psdata_OBER for abundance filtered data

```


```{r rarefaction curves, message=F, echo=T, eval=T, warning=T, include=T, cache=F}
# alpha rarefaction curve
source("scripts/ampvis2_internals.r")
source("scripts/amp_rankabundance.r")
source("scripts/amp_rarecurve.r")

# create combined metadata factor
sample_data(psdata_OBER_unfiltered)$combined = factor(paste0(
  sample_data(psdata_OBER_unfiltered)$filter_type, "-", 
  sample_data(psdata_OBER_unfiltered)$sample_type, "-", 
  sample_data(psdata_OBER_unfiltered)$sampling_time))

# show plot
amp_rarecurve(psdata_OBER_unfiltered, color = "combined", legend.position = "bottomright")

# save plot
pdf("figures/OBER_proj2_BODAC_rarefaction_curves.pdf", useDingbats = F, width = 6, height = 4)
amp_rarecurve(psdata_OBER_unfiltered, color = "combined", legend.position = "bottomright")
dev.off()

#amp_rarecurve(psdata_OBER, color = "combined", legend.position = "bottomright")
#amp_rarecurve(psdata_OBER, color = "Protocol", legend.position = "bottomright")

# difference in sample coverage (7.39)
max(sample_sums(psdata_OBER)/min(sample_sums(psdata_OBER)))

sample_sums(psdata_OBER) %>% as_tibble %>% arrange() %>% tail

```

```{r avg_rarefy psdata, message=F, echo=T, eval=T, warning=T, include=T, cache=F}

# summary statistics of dataset
summary(sample_sums(psdata_OBER)) %>% 
  enframe(name = "statistic", value = "read count") %>% 
  as_tibble() %>% kableExtra::kbl(caption = "summary statistics of sequence data set", centering = T, align = "l") %>% kableExtra::kable_classic()


# rarefy to 13092
  # create subset frequency matrix
  OBER_matrix <- as.matrix(t(otu_table(psdata_OBER)))
  
  # determine minimal sampling depth
  min_sample <- min(sample_sums(psdata_OBER))
  
  # rarefaction taking mean of 100 iterations
  set.seed(711)
  # OBER_rare13092 <- avgdist(OBER_matrix, d_method="bray", sample = min_sample, iterations = 100)
  # not using this: we also aim to calculate UniFrac
  source("scripts/avgrarefy.r")
  OBER_rare13092_table = avgrarefy(x=OBER_matrix, sample = min_sample, iterations = 100, seed = 711)

# create phyloseq object with rarefied data  
psdata_OBER_rare <- psdata_OBER
otu_rare = otu_table(data.frame(t(OBER_rare13092_table)), taxa_are_rows = TRUE)
otu_table(psdata_OBER_rare) <- otu_rare

```


```{r plot alpha diversity rare, message=F, echo=T, eval=T, warning=T, include=T, cache=F}

# calculate alpha diversity: richness & Shannon

# rarefied
alpha <- estimate_richness(psdata_OBER_rare, measures = c("Observed", "Chao1", "Shannon"))
alpha$sampleid <- row.names(alpha)
metadata = metadata %>% 
  dplyr::mutate(sampleid = sampleID) %>% 
  filter(sampleid %in% sample_names(psdata_OBER_rare))
alpha <- inner_join(metadata, alpha, by = "sampleid")
alpha$combined = factor(paste0(
  alpha$filter_type, "-", 
  alpha$sample_type, "-", 
  alpha$sampling_time))

alpha = 
alpha %>% 
  dplyr::mutate(combined = factor(combined, 
                           levels= c("BODAC_1-granule-before_backwash",
                                  "BODAC_1-granule-after_backwash",
                                  "BODAC_1-backwash-NA",
                                  "BODAC_2-granule-before_backwash",
                                  "BODAC_2-granule-after_backwash",
                                  "BODAC_2-backwash-NA")))

# summary statistics of number of samples per group
alpha %>% 
  group_by(filter_type, sampling_time, sample_type) %>% 
  count
  
# reformat dates
alpha2 = alpha %>% dplyr::mutate(date = lubridate::ymd(sampling_date), 
                         sampling_time = if_else(is.na(sampling_time), "after", sampling_time), 
                         month = as.numeric(as.character(month)),
                         month = lubridate::month(month, label = T),
                         year = as.factor(year), 
                         sample_type = factor(sample_type, levels = c("granule", "backwash")))

# plot alpha diversity
Chao1 <- alpha2 %>% 
ggplot(aes(x=date, y=Chao1)) +
  geom_point(aes(color = date, fill = date, shape = sampling_time, group = sampling_time), 
             size = 2, show.legend = T) + 
  geom_line(aes(group = sampling_time, color = date)) +
  scale_color_gradient(low = "lightblue", high = "dodgerblue") +
  scale_fill_gradient(low = "lightblue", high = "dodgerblue") +
  scale_shape_manual(values = c(19,17, 2)) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 0, hjust = 1)) +
  theme(#legend.text = element_markdown(),
        legend.key.size = unit(7, "pt"),
        axis.ticks.x = element_blank(), 
        strip.background = element_blank(),
        strip.placement = "outside",
        legend.position = "bottom",
        panel.border = element_rect(colour = "black", fill = NA)) +
  facet_wrap(~ filter_type + sample_type)

Shannon <- alpha2 %>% 
ggplot(aes(x=date, y=Shannon)) +
  geom_line(aes(group = sampling_time, color = date)) +
  geom_point(aes(color = date, shape = sampling_time, group = sampling_time), 
             size = 2, 
             fill = "white",
             show.legend = T) + 
  scale_color_gradient(low = "lightblue", high = "dodgerblue") +
  scale_fill_gradient(low = "lightblue", high = "dodgerblue") +
  scale_shape_manual(values = c(19,17, 2)) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 0, hjust = 0.5),
        #legend.text = element_markdown(),
        legend.key.size = unit(7, "pt"),
        strip.background = element_blank(),
        strip.placement = "outside",
        legend.position = "right",
        panel.border = element_rect(colour = "black", fill = NA)) +
  facet_wrap(~ filter_type + sample_type)

# create plot
prow = plot_grid(
  plot_grid(Chao1 + theme(legend.position = "none"), 
            Shannon + theme(legend.position = "none"),
                   align = "hv",
                   labels = c("A", "B"),
                   hjust = -1, 
                   ncol = 2),
  get_legend(Chao1), 
  nrow = 2 , 
  rel_heights = c(5, 1))

# show plot
prow

# save plot
ggsave(prow, filename = "figures/plot_alpha_div_OBER_rare13092.pdf", width = 11, height = 6)


```

```{r loss of alpha diversity, message=F, echo=T, eval=T, warning=T, include=T, cache=F, fig.width=4, fig.height=2}

# calculate loss of alpha diversity as a result of backwashing
chao_loss = 
alpha2 %>% 
  filter(sample_type == "granule") %>% 
  select(Chao1, Shannon, filter_type, sampling_time, month, year) %>% 
  pivot_longer(c(Chao1, Shannon), names_to = "alpha_metric", values_to = "value") %>% 
  pivot_wider(names_from = "sampling_time", values_from = "value") %>% 
  dplyr::mutate(loss = before_backwash - after_backwash) %>% 
  filter(alpha_metric == "Chao1") %>% 
  ggplot(aes(x = month, y = loss, color = year, fill = year)) +
    geom_point(size = 2, show.legend = T) + # position = position_jitterdodge(0.2)) +
    scale_color_manual(values = c(brewer.pal(6, "Dark2"))) +
    scale_fill_manual(values = c(brewer.pal(6, "Dark2"))) +
    scale_shape_manual(values = c(19,17, 2)) +
    theme_classic() +
    theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
    theme(legend.text = element_markdown(),
          legend.key.size = unit(7, "pt"),
          axis.ticks.x = element_blank(), 
          strip.background = element_blank(),
          strip.placement = "outside",
          legend.position = "right",
          panel.border = element_rect(colour = "black", fill = NA)) +
    facet_wrap(~ filter_type) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "darkred") +
  labs(y="Difference in ASV richness due to backwashing",
       x = NULL)
  
shannon_loss = 
alpha2 %>% 
  filter(sample_type == "granule") %>% 
  select(Chao1, Shannon, filter_type, sampling_time, month, year) %>% 
  pivot_longer(c(Chao1, Shannon), names_to = "alpha_metric", values_to = "value") %>% 
  pivot_wider(names_from = "sampling_time", values_from = "value") %>% 
  dplyr::mutate(loss = before_backwash - after_backwash) %>% 
  filter(alpha_metric == "Shannon") %>% 
  ggplot(aes(x = month, y = loss, color = year, fill = year)) +
    geom_point(size = 2, show.legend = T) + # position = position_jitterdodge(0.2)) +
    scale_color_manual(values = c(brewer.pal(6, "Dark2"))) +
    scale_fill_manual(values = c(brewer.pal(6, "Dark2"))) +
    scale_shape_manual(values = c(19,17, 2)) +
    theme_classic() +
    theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
    theme(legend.text = element_markdown(),
          legend.key.size = unit(7, "pt"),
          axis.ticks.x = element_blank(), 
          strip.background = element_blank(),
          strip.placement = "outside",
          legend.position = "right",
          panel.border = element_rect(colour = "black", fill = NA)) +
    facet_wrap(~ filter_type) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "darkred") +
  labs(y = "Difference in Shannon due to backwashing",
       x = NULL)


# create plot
prow_loss = plot_grid(
  plot_grid(chao_loss + theme(legend.position = "none"), 
            shannon_loss + theme(legend.position = "none"),
                   align = "hv",
                   labels = c("A", "B"),
                   hjust = -1, 
                   ncol = 2),
  get_legend(chao_loss), 
  ncol = 2 , 
  rel_widths = c(6, 1))

# save plot
ggsave(prow_loss, filename = "figures/plot_alpha_loss_in_granules_backwashing_OBER_rare13092.pdf", width = 11, height = 4)

# show plot
prow_loss

```




### ADD Alpha div on Genus level

### ADD Alpha div statistics

### Beta div using avgrare

```{r calculate avg beta diversity ASV granules, eval=T, echo=F, fig.height=3, fig.width=8, message=FALSE, warning=FALSE, cache=FALSE, include=T}

### Beta diversity analysis first
# input data  = psdata_OBER
psdata_OBER_beta_granules <-
  psdata_OBER %>% 
  subset_samples(sample_type == "granule") %>% 
  prune_taxa(taxa_sums(.)>0, .)

# save granule microbiome data for MP removal analysis
saveRDS(psdata_OBER_beta_granules, "output_data/psdata_OBER_beta_granules.rds")

# create subset frequency matrix
OBER_matrix_granules <- as.matrix(t(otu_table(psdata_OBER_beta_granules)))

# determine minimal sampling depth
min_sample_granules <- min(sample_sums(psdata_OBER_beta_granules))

# rarefaction taking mean of 100 iterations
set.seed(711)
OBER_rare13092_granules <- avgdist(OBER_matrix_granules, d_method="bray", sample = min_sample_granules, iterations = 100)
OBER_rare13092_jac_granules <- avgdist(OBER_matrix_granules, d_method="jaccard", sample = min_sample_granules, iterations = 100)

source("scripts/avgrarefy.r")
OBER_rare13092_table_granules = avgrarefy(x=OBER_matrix_granules, sample = min_sample_granules, iterations = 100, seed = 711)
# save rarefied table
saveRDS(OBER_rare13092_table_granules, "output_data/OBER_rare13092_table_granules.rds")

```

```{r adonis beta diversity ASV granules, eval=T, echo=F, fig.height=3, fig.width=8, message=FALSE, warning=FALSE, cache=FALSE, include=T}

# sample data
sam_data_granules <- data.frame(sample_data(psdata_OBER_beta_granules))

# calculate adonis permanova on granules only on ASV level Bray-Curtis diss

adonis_bc_granules = adonis2(OBER_rare13092_granules ~ filter_type * sampling_date + sampling_time, permutations = 999, data = sam_data_granules, by = )

```


```{r calculate avg beta diversity ASV backwash water, eval=T, echo=F, fig.height=3, fig.width=8, message=FALSE, warning=FALSE, cache=FALSE, include=T}

### Beta diversity analysis first
# input data  = psdata_OBER
psdata_OBER_beta_backwash <-
  psdata_OBER %>% 
  subset_samples(sample_type == "backwash") %>% 
  prune_taxa(taxa_sums(.)>0, .)

# create subset frequency matrix
OBER_matrix_backwash <- as.matrix(t(otu_table(psdata_OBER_beta_backwash)))

# determine minimal sampling depth
min_sample_backwash <- min(sample_sums(psdata_OBER_beta_backwash))

# rarefaction taking mean of 100 iterations
set.seed(711)
OBER_rare21227_backwash <- avgdist(OBER_matrix_backwash, d_method="bray", sample = min_sample_backwash, iterations = 100)
OBER_rare21227_jac_backwash <- avgdist(OBER_matrix_backwash, d_method="jaccard", sample = min_sample_backwash, iterations = 100)

source("scripts/avgrarefy.r")
OBER_rare21227_table_backwash = avgrarefy(x=OBER_matrix_backwash, sample = min_sample_backwash, iterations = 100, seed = 711)

```


```{r beta diversity without ordination}

# can be split
# avgdist Bray curtis dist matrix to use:
psdata_OBER_beta_all <-
  psdata_OBER

# create subset frequency matrix
OBER_matrix_all <- as.matrix(t(otu_table(psdata_OBER_beta_all)))

# determine minimal sampling depth
min_sample_all <- min(sample_sums(psdata_OBER_beta_all))

# rarefaction taking mean of 100 iterations
set.seed(711)
OBER_rare13092_all <- avgdist(OBER_matrix_all, d_method="bray", sample = min_sample_all, iterations = 100)
OBER_rare13092_jac_all <- avgdist(OBER_matrix_all, d_method="jaccard", sample = min_sample_all, iterations = 100)

source("scripts/avgrarefy.r")
OBER_rare13092_table_all = avgrarefy(x=OBER_matrix_all, sample = min_sample_all, iterations = 100, seed = 711)


# reshape to long format
bray_long_all = 
OBER_rare13092_all %>% 
  as.matrix() %>% 
  as_tibble(rownames = "sample_a") %>% 
  pivot_longer(-sample_a, names_to = "sample_b", values_to = "distance") %>% 
  dplyr::mutate(metric = "braycurtis")

jaccard_long_all =
OBER_rare13092_jac_all %>% 
  as.matrix() %>% 
  as_tibble(rownames = "sample_a") %>% 
  pivot_longer(-sample_a, names_to = "sample_b", values_to = "distance") %>% 
  dplyr::mutate(metric = "jaccard")


# define consecutive sampling moments
consecutive_months = c("Mar_to_Jun", "Jun_to_Sep", "Sep_to_Dec", "Dec_to_Mar")
consecutive_monthsYears = c("Sep_2019_to_Dec_2019",
                        "Dec_2019_to_Mar_2020",
                        "Mar_2020_to_Jun_2020",
                        "Jun_2020_to_Sep_2020",
                        "Sep_2020_to_Dec_2020",
                        "Dec_2020_to_Mar_2021",
                        "Mar_2021_to_Jun_2021",
                        "Jun_2021_to_Sep_2021")

# reshape distance data and combine with metadata
all_dists_all =
bind_rows(bray_long_all, jaccard_long_all) %>% 
  filter(sample_a != sample_b) %>% # remove self-comparisons
  inner_join(., alpha2 %>% select(sampleID,sampling_date:sampling_time), by = c("sample_a" = "sampleID")) %>% 
  dplyr::mutate(month_year = paste0(month,"_", year)) %>% 
  rename_with(., .fn = ~paste0(.,"_a"), .cols = names(.)[-c(1:4)]) %>% # tag metadata to first sample
  inner_join(., alpha2 %>% select(sampleID,sampling_date:sampling_time), by = c("sample_b" = "sampleID")) %>%
  dplyr::mutate(month_year = paste0(month,"_", year)) %>% 
  rename_with(., .fn = ~paste0(.,"_b"), .cols = names(.)[c(14:ncol(.))]) %>% # tag metadata to second sample
  dplyr::mutate(consec_months = paste0(month_a,"_to_", month_b)) %>% 
  dplyr::mutate(consec_monthsY_a = paste0(month_year_a,"_to_", month_year_b)) %>%
  filter(consec_months %in% consecutive_months) %>% # select only distances between consecutive samplings
  dplyr::mutate(consec_months_year_a = factor(paste0(consec_months,"_in_", year_a), 
                                       levels = c("Sep_to_Dec_in_2019",
                                                  "Dec_to_Mar_in_2019",
                                                  "Mar_to_Jun_in_2020",
                                                  "Jun_to_Sep_in_2020",
                                                  "Sep_to_Dec_in_2020",
                                                  "Dec_to_Mar_in_2020",
                                                  "Mar_to_Jun_in_2021",
                                                  "Jun_to_Sep_in_2021"))) %>% 
  filter(consec_monthsY_a %in% consecutive_monthsYears) %>% 
  dplyr::mutate(consec_monthsY_a = factor(consec_monthsY_a, 
                                       levels = consecutive_monthsYears)) %>% 
  filter(sample_type_a == "granule", # select only within sample-type comparisons
         sample_type_b == "granule", # select only within sample-type comparisons
         filter_type_a == filter_type_b, # select only within filter-type comparisons
         sampling_time_a == "after_backwash", # select only within backwashing-subgroup comparisons
         sampling_time_b == "after_backwash",
         year_a == year_b # compare only samples within a year
         ) 

all_dists_all %>% 
  ggplot(aes(x = consec_monthsY_a, y = distance, color = year_a)) +
    geom_point(size = 2, show.legend = T) + # position = position_jitterdodge(0.2)) +
    scale_color_manual(values = c(brewer.pal(6, "Dark2"))) +
    scale_fill_manual(values = c(brewer.pal(6, "Dark2"))) +
    scale_shape_manual(values = c(19,17, 2)) +
    theme_classic() +
    theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
    theme(legend.text = element_markdown(),
          legend.key.size = unit(7, "pt"),
          axis.ticks.x = element_blank(), 
          strip.background = element_blank(),
          strip.placement = "outside",
          legend.position = "right",
          panel.border = element_rect(colour = "black", fill = NA)) +
    facet_wrap(~ metric + filter_type_a) +
    labs(y = "Distance",
         x = NULL)

# TODO: plot for backwashwater if wanted


```

```{r calculate avg beta diversity Family, eval=T, echo=F, fig.height=3, fig.width=8, message=FALSE, warning=FALSE, cache=FALSE, include=T}

### Beta diversity analysis first
# input data  = psdata_OBER
psdata_OBER_beta_fam <-
  psdata_OBER %>% 
  subset_samples(sample_type == "granule") %>% 
  prune_taxa(taxa_sums(.)>0, .) %>% 
  tax_glom(., "Family")

# create subset frequency matrix
OBER_matrix_fam <- as.matrix(t(otu_table(psdata_OBER_beta_fam)))

# determine minimal sampling depth
min_sample <- min(sample_sums(psdata_OBER_beta_fam))

# rarefaction taking mean of 100 iterations
set.seed(711)
OBER_rare13092_fam <- avgdist(OBER_matrix_fam, d_method="bray", sample = min_sample, iterations = 100)
source("scripts/avgrarefy.r")
OBER_rare13092_table_fam = avgrarefy(x=OBER_matrix_fam, sample = min_sample, iterations = 100, seed = 711)

```


```{r plot avg beta diversity ASV granules, eval=T, echo=F, fig.height=3, fig.width=8, message=FALSE, warning=FALSE, cache=FALSE, include=T}

## Objects are not named as granules only!
# PCoA on rarefied data
pcoa <- cmdscale(OBER_rare13092, k = 2, eig = T, add = T)
positions <- pcoa$points
colnames(positions) <- c("pcoa1", "pcoa2")
 
# PCoA species scores
spe.wa <- wascores(pcoa$points[,1:2], OBER_rare13092_table)
colnames(spe.wa) <- c("pcoa1", "pcoa2")

# Add taxonomic information to species scores
tax_beta_div <-
  tax_table(psdata_OBER_beta) %>% 
  as.data.frame() %>% 
  as_tibble(rownames = "taxon")
spe.scores <- spe.wa %>% 
  as_tibble(rownames = "taxon") %>% 
  inner_join(., tax_beta_div, by = "taxon") %>% 
  select(taxon, Family, Genus, pcoa1, pcoa2)
  

# percent explained by axes
percent_explained <- 100* pcoa$eig / sum(pcoa$eig)

# percent explained labeling
pretty_pe <- format(round(percent_explained[1:2], digits = 1), nsmall =1, trim=T)

# axis labels 
labs <- c(glue("PCoA 1 ({pretty_pe[1]}%)"),
          glue("PCoA 2 ({pretty_pe[2]}%)"))

# select top 25 abundant taxa across the dataset
source("scripts/ps_abund_top_info.r")
topn = 25
ASV_info_abund <- ps_abund_top_info(psdata_OBER_beta, top_nr = topn)

# filteer species scores for top 10 taxa
spe.scores_top = spe.scores %>% filter(taxon %in% ASV_info_abund$taxon) %>% 
  dplyr::mutate(Genus = if_else(is.na(Genus), paste0("Genus of ", Family), Genus)) %>% 
  inner_join(., ASV_info_abund %>% select(taxon, abund), by = "taxon") %>% 
  dplyr::mutate(abund_sqrt_1000r = sqrt(abund/1000))

# plot samples and top25 species scores
plot_beta_tbl <- positions %>%  
  as_tibble(rownames = "samples") %>% 
  inner_join(., metadata_cleaned, by = c("samples"="sampleid")) 

# view number of samples per group
# plot_beta_tbl %>%
#   group_by(filter_type, sample_type, sampling_time) %>%
#   summarise(n=n())

plot_beta_all = 
plot_beta_tbl %>% 
  ggplot(aes(x=pcoa1, y=pcoa2)) +
  geom_vline(xintercept = 0, linetype = 3, color = "grey80") +
  geom_hline(yintercept = 0, linetype = 3, color = "grey80") +
  geom_point(aes(shape=filter_type, color=filter_type, fill=filter_type)) +
  geom_segment(
      data = spe.scores_top,
      aes(
        x = 0, 
        y = 0,
        xend = pcoa1, 
        yend = pcoa2
      ),
      arrow = arrow(length = unit(1, "mm")),
      color = "grey80") +
  # geom_point(data = spe.scores_top, 
  #            aes(x=pcoa1, 
  #                y=pcoa2, 
  #                label=Genus, 
  #                size = abund_sqrt_1000r, 
  #                alpha=1-(1/abund_sqrt_1000r)
  #                ), 
  #            color = "grey80",
  #            show.legend = c(alpha = NULL)) +
  geom_text(data=spe.scores_top, 
            aes(label=Genus, 
            hjust = ifelse(pcoa1>=0, 0, 1),
            nudge_x = ifelse(pcoa1>=0, -0.5, 0.5)),
            color = "grey70", 
            size = 4, 
            check_overlap = F) +
  scale_shape_manual(values = c(21, 22, 24, 1, 0, 2)) +
  scale_color_manual(values = brewer.pal(6, "Dark2")) +
  scale_fill_manual(values = brewer.pal(6, "Dark2"), guide= "none") +
  # guides(shape = guide_legend(title = "Condition & Timepoint",  override.aes = list(
  #   shape = c(21, 22, 24, 1, 0, 2),
  #   fill = c(rep("black", 3), rep("white", 3))))) +
  labs(x = labs[1], y=labs[2]) +
  # coord_cartesian(xlim = c(-0.5, NA)) +
  theme_classic() +
  facet_wrap(~year, ncol = 3) +
  theme(strip.background = element_rect(colour=NA, fill=NA))


# extract and compile plots and legend 
beta_figs = plot_grid(plot_beta_all + theme(legend.position = "none"),
                       get_legend(plot_beta_all),
                       ncol = 2,
                       rel_widths = c(3,0.5))

# show plpt
beta_figs

# save plot
ggsave(plot = beta_figs, 
       file = stringr::str_glue("figures/{proj}_beta_div_PCoA_BrayCurtis_topN{topn}_granules.pdf"), 
       width = 8, 
       height = 6)
   
```  

```{r plot avg beta diversity ASV timepath granules, eval=T, echo=F, fig.height=3, fig.width=8, message=FALSE, warning=FALSE, cache=FALSE, include=T}

library(ggrepel)

# PCoA on rarefied data
pcoa_granules <- cmdscale(OBER_rare13092_granules, k = 2, eig = T, add = T)
positions_granules <- pcoa_granules$points
colnames(positions_granules) <- c("pcoa1", "pcoa2")

# pcoa data reshaping
plot_beta_tbl_granules <- positions_granules %>%  
  as_tibble(rownames = "samples") %>% 
  inner_join(., metadata_cleaned, by = c("samples"="sampleid")) %>% 
  dplyr::mutate(combi = factor(paste0(filter_type, "_", sampling_time), levels = c("BODAC_1_before_backwash", "BODAC_1_after_backwash",  "BODAC_2_before_backwash", "BODAC_2_after_backwash"))) 

# percent explained by axes
percent_explained_granules <- 100* pcoa_granules$eig / sum(pcoa_granules$eig)

# percent explained labeling
pretty_pe_granules <- format(round(percent_explained_granules[1:2], digits = 1), nsmall =1, trim=T)

# axis labels 
labs <- c(glue("PCoA 1 ({pretty_pe_granules[1]}%)"),
          glue("PCoA 2 ({pretty_pe_granules[2]}%)"))

p = 
  plot_beta_tbl_granules %>% 
  dplyr::mutate(sampling_date = ymd(sampling_date),
         sampling_time = factor(sampling_time, levels = c("before_backwash", "after_backwash")),
         month = month.abb[month],
         month_year = paste0(month, " ", year)) %>% 
  ggplot(aes(x=pcoa1, y=pcoa2)) +
  geom_vline(xintercept = 0, linetype = 3, color = "grey80") +
  geom_hline(yintercept = 0, linetype = 3, color = "grey80") +
  geom_point(aes(color=sampling_date), size =3) +
  geom_path(aes(color = sampling_date), size = 1.5) +
  scale_color_gradient(low = "lightblue", high = "dodgerblue", guide = "none") +
  scale_y_continuous(expand = c(-0.3, 0.4)) +
  facet_grid(cols=vars(combi)) +
  labs(x = labs[1], y=labs[2]) +
  theme_classic()
  
p = p +  geom_text_repel(aes(label = month_year, color = sampling_date))

print(p)

# save plot
ggsave(plot = p, 
       file = stringr::str_glue("figures/{proj}_beta_div_PCoA_BrayCurtis_granules_timepath.pdf"), 
       width = 10, 
       height = 4)

```

```{r plot avg beta diversity ASV timepath backwash, eval=T, echo=F, fig.height=3, fig.width=8, message=FALSE, warning=FALSE, cache=FALSE, include=T}

library(ggrepel)

# PCoA on rarefied data
pcoa_backwash <- cmdscale(OBER_rare13092_backwash, k = 2, eig = T, add = T)
positions_backwash <- pcoa_backwash$points
colnames(positions_backwash) <- c("pcoa1", "pcoa2")

plot_beta_tbl_backwash <- positions_backwash %>%  
  as_tibble(rownames = "samples") %>% 
  inner_join(., metadata_cleaned, by = c("samples"="sampleid")) 

# percent explained by axes
percent_explained_backwash <- 100* pcoa_backwash$eig / sum(pcoa_backwash$eig)

# percent explained labeling
pretty_pe_backwash <- format(round(percent_explained_backwash[1:2], digits = 1), nsmall =1, trim=T)

# axis labels 
labs <- c(glue("PCoA 1 ({pretty_pe_backwash[1]}%)"),
          glue("PCoA 2 ({pretty_pe_backwash[2]}%)"))

q = 
  plot_beta_tbl_backwash %>% 
  dplyr::mutate(sampling_date = ymd(sampling_date),
         sampling_time = factor(sampling_time, levels = c("before_backwash", "after_backwash")),
         month = month.abb[month],
         month_year = paste0(month, " ", year)) %>% 
  ggplot(aes(x=pcoa1, y=pcoa2)) +
  geom_vline(xintercept = 0, linetype = 3, color = "grey80") +
  geom_hline(yintercept = 0, linetype = 3, color = "grey80") +
  geom_point(aes(color=sampling_date), size =3) +
  geom_path(aes(group = filter_type, color = sampling_date), size = 1.5) +
  scale_color_gradient(low = "lightblue", high = "dodgerblue", guide = "none") +
  scale_y_continuous(expand = c(-0.3, 0.4)) +
  labs(x = labs[1], y=labs[2]) +
  #facet_grid(cols=vars(filter_type)) +
  theme_classic()
  
q = q +  geom_text_repel(aes(label = month_year, color = sampling_date))

print(q)

# save plot
ggsave(plot = q, 
       file = stringr::str_glue("figures/{proj}_beta_div_PCoA_BrayCurtis_backwash_timepath.pdf"), 
       width = 6, 
       height = 4)

```

```{r plot avg beta diversity Family, eval=F, echo=F, fig.height=3, fig.width=8, message=FALSE, warning=FALSE, cache=FALSE, include=F}

# PCoA on rarefied data
pcoa_fam <- cmdscale(OBER_rare13092_fam, k = 2, eig = T, add = T)
positions_fam <- pcoa_fam$points
colnames(positions_fam) <- c("pcoa1", "pcoa2")
 
# PCoA species scores
spe.wa_fam <- wascores(pcoa_fam$points[,1:2], OBER_rare13092_table_fam)
colnames(spe.wa_fam) <- c("pcoa1", "pcoa2")

# Add taxonomic information to species scores
tax_beta_div_fam <-
  tax_table(psdata_OBER_beta_fam) %>% 
  as.data.frame() %>% 
  as_tibble(rownames = "taxon")
spe.scores_fam <- spe.wa_fam %>% 
  as_tibble(rownames = "taxon") %>% 
  inner_join(., tax_beta_div_fam, by = "taxon") %>% 
  select(taxon, Family, Genus, pcoa1, pcoa2)
  

# percent explained by axes
percent_explained_fam <- 100* pcoa_fam$eig / sum(pcoa_fam$eig)

# percent explained labeling
pretty_pe_fam <- format(round(percent_explained_fam[1:2], digits = 1), nsmall =1, trim=T)

# axis labels 
labs_fam <- c(glue("PCoA 1 ({pretty_pe_fam[1]}%)"),
          glue("PCoA 2 ({pretty_pe_fam[2]}%)"))

# select top 15 abundant taxa across the dataset
source("scripts/ps_abund_top_info.r")
topn = 15
ASV_info_abund_fam <- ps_abund_top_info(psdata_OBER_beta_fam, top_nr = topn)

# filteer species scores for top 10 taxa
spe.scores_top_fam = spe.scores_fam %>% filter(taxon %in% ASV_info_abund_fam$taxon) %>% 
  dplyr::mutate(Genus = if_else(is.na(Genus), paste0("Genus of ", Family), Genus)) %>% 
  inner_join(., ASV_info_abund_fam %>% select(taxon, abund), by = "taxon") %>% 
  dplyr::mutate(abund_sqrt_1000r = sqrt(abund/1000))

# plot samples and top25 species scores
plot_beta_tbl_fam <- positions_fam %>%  
  as_tibble(rownames = "samples") %>% 
  inner_join(., metadata_cleaned, by = c("samples"="sampleid")) 

# view number of samples per group
# plot_beta_tbl %>%
#   group_by(filter_type, sample_type, sampling_time) %>%
#   summarise(n=n())

plot_beta_all_fam = 
plot_beta_tbl_fam %>% 
  ggplot(aes(x=pcoa1, y=pcoa2)) +
  geom_vline(xintercept = 0, linetype = 3, color = "grey80") +
  geom_hline(yintercept = 0, linetype = 3, color = "grey80") +
  geom_point(aes(shape=filter_type, color=filter_type, fill=filter_type)) +
  geom_segment(
      data = spe.scores_top_fam,
      aes(
        x = 0, 
        y = 0,
        xend = pcoa1, 
        yend = pcoa2
      ),
      arrow = arrow(length = unit(1, "mm")),
      color = "grey80") +
  # geom_point(data = spe.scores_top, 
  #            aes(x=pcoa1, 
  #                y=pcoa2, 
  #                label=Genus, 
  #                size = abund_sqrt_1000r, 
  #                alpha=1-(1/abund_sqrt_1000r)
  #                ), 
  #            color = "grey80",
  #            show.legend = c(alpha = NULL)) +
  geom_text(data=spe.scores_top_fam, 
            aes(label=Genus, 
            hjust = ifelse(pcoa1>=0, 0, 1),
            nudge_x = ifelse(pcoa1>=0, -0.5, 0.5)),
            color = "grey70", 
            size = 4, 
            check_overlap = F) +
  scale_shape_manual(values = c(21, 22, 24, 1, 0, 2)) +
  scale_color_manual(values = brewer.pal(6, "Dark2")) +
  scale_fill_manual(values = brewer.pal(6, "Dark2"), guide= "none") +
  # guides(shape = guide_legend(title = "Condition & Timepoint",  override.aes = list(
  #   shape = c(21, 22, 24, 1, 0, 2),
  #   fill = c(rep("black", 3), rep("white", 3))))) +
  labs(x = labs[1], y=labs[2]) +
  # coord_cartesian(xlim = c(-0.5, NA)) +
  theme_classic() +
  facet_wrap(~year, ncol = 3) +
  theme(strip.background = element_rect(colour=NA, fill=NA))


# extract and compile plots and legend 
beta_figs_fam = plot_grid(plot_beta_all_fam + theme(legend.position = "none"),
                       get_legend(plot_beta_all_fam),
                       ncol = 2,
                       rel_widths = c(3,0.5))

# show plpt
beta_figs_fam

# save plot
ggsave(plot = beta_figs_fam, 
       file = stringr::str_glue("figures/{proj}_beta_div_PCoA_BrayCurtis_topN{topn}_backwash_fam.pdf"), 
       width = 14, 
       height = 6)
   
```  


### Core community stability based on Bray-Curtis dissimilarities (1-x)
```{r calculate core communities, eval=T, echo=F, fig.height=3, fig.width=5, message=FALSE, warning=FALSE, cache=FALSE, include=T}

# following https://microbiome.github.io/tutorials/Core.html

## input data
pseq <- psdata_OBER_rare
# Calculate compositional version of the data
# (relative abundances)
pseq.rel <- microbiome::transform(pseq, "compositional")

# define core communities per type of sample
pseq_granules = pseq.rel %>% 
  subset_samples(., sample_type == "granule") %>% 
  prune_taxa(taxa_sums(.)>0,.)

pseq_water = 
  pseq.rel %>% 
  subset_samples(., sample_type == "backwash") %>% 
  prune_taxa(taxa_sums(.)>0,.)

# core microbiome = >90% prevalent taxa
pseq.core_granules <- core(pseq_granules, detection = 0, prevalence = .90)
pseq.core_water <- core(pseq_water, detection = 0, prevalence = .90)

core90_granules_abund = pseq.core_granules %>% psmelt()
core90_water_abund = pseq.core_water %>% psmelt()

# granules: # ~23-57% abundance
stats_core.abundance_granules <- summary(sample_sums(pseq.core_granules)) 
# water: # ~10-45% abundance
stats_core.abundance_water <- summary(sample_sums(pseq.core_water))


```

```{r core stability granules, eval=T, echo=F, fig.height=3, fig.width=5, message=FALSE, warning=FALSE, cache=FALSE, include=T}
# tax info
tax.df <- as.data.frame(tax_table(psdata_OBER_rare))
tax.df$OTU <- rownames(tax.df)

# granule tax info
core.taxa_granules <- taxa(pseq.core_granules)
core.taxa.class_granules <- 
  dplyr::filter(tax.df, rownames(tax.df) %in% core.taxa_granules) %>% 
  inner_join(., core90_granules_abund %>% select(OTU, Sample, Abundance), by = "OTU") %>%   select(Sample, OTU, everything()) %>% 
  dplyr::mutate(counts = Abundance*13092)
  
# ASV table core community granules
ASV_table_core90_granules = 
core.taxa.class_granules %>% 
  select(Sample, OTU, counts) %>% 
  pivot_wider(names_from = "OTU", values_from = "counts", values_fill = 0) %>% 
  data.frame(row.names = 1) %>% as.matrix() %>% round()

# beta diversity

# avgdist Bray curtis dist matrix to use:
bray_core90_granules = vegdist(ASV_table_core90_granules, method = "bray")

# reshape to long format
bray_core90_granules_long = 
bray_core90_granules %>% 
  as.matrix() %>% 
  as_tibble(rownames = "sample_a") %>% 
  pivot_longer(-sample_a, names_to = "sample_b", values_to = "distance") %>% 
  dplyr::mutate(metric = "braycurtis")


# define consecutive sampling moments
consecutive_months = c("Mar_to_Jun", "Jun_to_Sep", "Sep_to_Dec", "Dec_to_Mar")
consecutive_monthsYears = c(
                        "Sep_2019_to_Dec_2019",
                        "Dec_2019_to_Mar_2020",
                        "Mar_2020_to_Jun_2020",
                        "Jun_2020_to_Sep_2020",
                        "Sep_2020_to_Dec_2020",
                        "Dec_2020_to_Mar_2021",
                        "Mar_2021_to_Jun_2021",
                        "Jun_2021_to_Sep_2021")

# reshape distance data and combine with metadata
all_dists_core90_granules =
bray_core90_granules_long %>% 
  filter(sample_a != sample_b) %>% # remove self-comparisons
  inner_join(., alpha2 %>% select(sampleID,sampling_date:sampling_time), by = c("sample_a" = "sampleID")) %>% 
  dplyr::mutate(month_year = paste0(month,"_", year)) %>% 
  rename_with(., .fn = ~paste0(.,"_a"), .cols = names(.)[-c(1:4)]) %>% # tag metadata to first sample
  inner_join(., alpha2 %>% select(sampleID,sampling_date:sampling_time), by = c("sample_b" = "sampleID")) %>%
  dplyr::mutate(month_year = paste0(month,"_", year)) %>% 
  rename_with(., .fn = ~paste0(.,"_b"), .cols = names(.)[c(14:ncol(.))]) %>% # tag metadata to second sample
  dplyr::mutate(consec_months = paste0(month_a,"_to_", month_b)) %>% 
  dplyr::mutate(consec_monthsY_a = paste0(month_year_a,"_to_", month_year_b)) %>%
  filter(consec_months %in% consecutive_months) %>% # select only distances between consecutive samplings
  dplyr::mutate(consec_months_year_a = factor(paste0(consec_months,"_in_", year_a), 
                                       levels = c("Sep_to_Dec_in_2019",
                                                  "Dec_to_Mar_in_2019",
                                                  "Mar_to_Jun_in_2020",
                                                  "Jun_to_Sep_in_2020",
                                                  "Sep_to_Dec_in_2020",
                                                  "Dec_to_Mar_in_2020",
                                                  "Mar_to_Jun_in_2021",
                                                  "Jun_to_Sep_in_2021"))) %>% 
  filter(consec_monthsY_a %in% consecutive_monthsYears) %>% 
  dplyr::mutate(consec_monthsY_a = factor(consec_monthsY_a, 
                                       levels = consecutive_monthsYears)) %>% 
  filter(sample_type_a == "granule", # select only within sample-type comparisons
         sample_type_b == "granule", # select only within sample-type comparisons
         filter_type_a == filter_type_b, # select only within filter-type comparisons
         sampling_time_a == "after_backwash", # select only within backwashing-subgroup comparisons
         sampling_time_b == "after_backwash"
         #year_a == year_b # compare only samples within a year
         ) %>% 
  dplyr::mutate(stability = 1-distance)

plot_stability_core90_granules = 
all_dists_core90_granules %>% 
  ggplot(aes(x = consec_monthsY_a, y = stability, color = year_a)) +
    geom_col(aes(fill=year_a), show.legend = F) +
    geom_point(size = 2, show.legend = T) + # position = position_jitterdodge(0.2)) +
    scale_color_manual(values = c(brewer.pal(6, "Dark2"))) +
    scale_fill_manual(values = c(brewer.pal(6, "Dark2"))) +
    scale_shape_manual(values = c(19,17, 2)) +
    theme_classic() +
    theme(axis.text.x = element_text(angle = 0, hjust = 0.5)) +
    theme(legend.text = element_markdown(),
          legend.key.size = unit(7, "pt"),
          axis.ticks.x = element_blank(), 
          strip.background = element_blank(),
          strip.placement = "outside",
          legend.position = "right",
          panel.border = element_rect(colour = "black", fill = NA)) +
    facet_wrap(~ metric + filter_type_a, ncol = 1) +
    labs(y = "Stability \n(1 = identical community compositions)",
         x = NULL) +
  coord_flip()

ggsave(plot_stability_core90_granules, 
       filename = "figures/Stability_core90_granules.pdf", width = 5, height = 5)

```

```{r core stability water, eval=T, echo=F, fig.height=3, fig.width=5, message=FALSE, warning=FALSE, cache=FALSE, include=T}

# tax info
tax.df <- as.data.frame(tax_table(psdata_OBER_rare))
tax.df$OTU <- rownames(tax.df)

# granule tax info
core.taxa_water <- taxa(pseq.core_water)
core.taxa.class_water <- 
  dplyr::filter(tax.df, rownames(tax.df) %in% core.taxa_water) %>% 
  inner_join(., core90_water_abund %>% select(OTU, Sample, Abundance), by = "OTU") %>%   select(Sample, OTU, everything()) %>% 
  dplyr::mutate(counts = Abundance*13092)
  
# ASV table core community water
ASV_table_core90_water = 
core.taxa.class_water %>% 
  select(Sample, OTU, counts) %>% 
  pivot_wider(names_from = "OTU", values_from = "counts", values_fill = 0) %>% 
  data.frame(row.names = 1) %>% as.matrix() %>% round()

# beta diversity

# avgdist Bray curtis dist matrix to use:
bray_core90_water = vegdist(ASV_table_core90_water, method = "bray")

# reshape to long format
bray_core90_water_long = 
bray_core90_water %>% 
  as.matrix() %>% 
  as_tibble(rownames = "sample_a") %>% 
  pivot_longer(-sample_a, names_to = "sample_b", values_to = "distance") %>% 
  dplyr::mutate(metric = "braycurtis")


# define consecutive sampling moments
consecutive_months = c("Mar_to_Jun", "Jun_to_Sep", "Sep_to_Dec", "Dec_to_Mar")
consecutive_monthsYears = c(
                        "Sep_2019_to_Dec_2019",
                        "Dec_2019_to_Mar_2020",
                        "Mar_2020_to_Jun_2020",
                        "Jun_2020_to_Sep_2020",
                        "Sep_2020_to_Dec_2020",
                        "Dec_2020_to_Mar_2021",
                        "Mar_2021_to_Jun_2021",
                        "Jun_2021_to_Sep_2021")

# reshape distance data and combine with metadata
all_dists_core90_water =
bray_core90_water_long %>% 
  filter(sample_a != sample_b) %>% # remove self-comparisons
  inner_join(., alpha2 %>% select(sampleID,sampling_date:sampling_time), by = c("sample_a" = "sampleID")) %>% 
  dplyr::mutate(month_year = paste0(month,"_", year)) %>% 
  rename_with(., .fn = ~paste0(.,"_a"), .cols = names(.)[-c(1:4)]) %>% # tag metadata to first sample
  inner_join(., alpha2 %>% select(sampleID,sampling_date:sampling_time), by = c("sample_b" = "sampleID")) %>%
  dplyr::mutate(month_year = paste0(month,"_", year)) %>% 
  rename_with(., .fn = ~paste0(.,"_b"), .cols = names(.)[c(14:ncol(.))]) %>% # tag metadata to second sample
  dplyr::mutate(consec_months = paste0(month_a,"_to_", month_b)) %>% 
  dplyr::mutate(consec_monthsY_a = paste0(month_year_a,"_to_", month_year_b)) %>%
  filter(consec_months %in% consecutive_months) %>% # select only distances between consecutive samplings
  dplyr::mutate(consec_months_year_a = factor(paste0(consec_months,"_in_", year_a), 
                                       levels = c("Sep_to_Dec_in_2019",
                                                  "Dec_to_Mar_in_2019",
                                                  "Mar_to_Jun_in_2020",
                                                  "Jun_to_Sep_in_2020",
                                                  "Sep_to_Dec_in_2020",
                                                  "Dec_to_Mar_in_2020",
                                                  "Mar_to_Jun_in_2021",
                                                  "Jun_to_Sep_in_2021"))) %>% 
  filter(consec_monthsY_a %in% consecutive_monthsYears) %>% 
  dplyr::mutate(consec_monthsY_a = factor(consec_monthsY_a, 
                                       levels = consecutive_monthsYears)) %>% 
  filter(sample_type_a == "backwash", # select only within sample-type comparisons
         sample_type_b == "backwash", # select only within sample-type comparisons
         filter_type_a == filter_type_b, # select only within filter-type comparisons
         sampling_time_a == "after", # select only within backwashing-subgroup comparisons
         sampling_time_b == "after"
         #year_a == year_b # compare only samples within a year
         ) %>% 
  dplyr::mutate(stability = 1-distance)

plot_stability_core90_water = 
all_dists_core90_water %>% 
  ggplot(aes(x = consec_monthsY_a, y = stability, color = year_a)) +
    geom_col(aes(fill=year_a), show.legend = F) +
    geom_point(size = 2, show.legend = T) + # position = position_jitterdodge(0.2)) +
    scale_color_manual(values = c(brewer.pal(6, "Dark2"))) +
    scale_fill_manual(values = c(brewer.pal(6, "Dark2"))) +
    scale_shape_manual(values = c(19,17, 2)) +
    theme_classic() +
    theme(axis.text.x = element_text(angle = 0, hjust = 0.5)) +
    theme(legend.text = element_markdown(),
          legend.key.size = unit(7, "pt"),
          axis.ticks.x = element_blank(), 
          strip.background = element_blank(),
          strip.placement = "outside",
          legend.position = "right",
          panel.border = element_rect(colour = "black", fill = NA)) +
    facet_wrap(~ metric + filter_type_a, ncol = 1) +
    labs(y = "Stability \n(1 = identical community compositions)",
         x = NULL) +
  coord_flip()

ggsave(plot_stability_core90_water, 
       filename = "figures/Stability_core90_water.pdf", width = 5, height = 5)

```


### Top ASVs relative abundances over time (rarefied)

```{r plot top ASVs granules, eval=T, echo=F, fig.height=6, fig.width=10, message=FALSE, warning=FALSE, cache=FALSE, include=T}

OBER_rare13092_table_granules_long_ASV = 
OBER_rare13092_table_granules %>% 
  as_tibble(rownames = "sampleID") %>% 
  rowwise() %>% dplyr::mutate(sample_sums = sum(c_across(2:ncol(.)))) %>% 
  mutate_at(vars(-sampleID, -sample_sums), funs(. / sample_sums)) %>%
  inner_join(., alpha2, by = "sampleID") %>% 
  select(sample_sums, colnames(alpha2), everything()) %>% 
  pivot_longer(cols = c(`9d86d845ef6790bf04ed6d8fffde4ab2`:ncol(.)), 
               names_to = "ASV", 
               values_to = "rel_abund")


top10_ASVs_granules = 
OBER_rare13092_table_granules_long_ASV %>% 
  #select(sampleID, ASV, rel_abund) %>%
  inner_join(., tax_beta_div %>% dplyr::rename(ASV = "taxon"), by = "ASV") %>% 
  dplyr::mutate(tax_label = paste0(Class, "__", Order, "__",Family, "__", Genus)) %>% 
  group_by(tax_label, date,filter_type, sampling_time, sampleID) %>% 
  summarise(rel_abund = sum(rel_abund)) %>% 
  ungroup() %>% 
  group_by(sampleID) %>% 
  arrange(-rel_abund, .by_group = T) %>% 
  slice_head(n=10) %>% 
  pull(tax_label) %>% unique()


OBER_rare13092_table_granules_long_ASV %>% 
  #select(sampleID, ASV, rel_abund) %>%
  inner_join(., tax_beta_div %>% dplyr::rename(ASV = "taxon"), by = "ASV") %>% 
  dplyr::mutate(tax_label = paste0(Class, "__", Order, "__",Family, "__", Genus)) %>% 
  group_by(tax_label, date, filter_type, sampling_time, sampleID, Phylum, Class, Order, Family, Genus) %>% 
  summarise(rel_abund = sum(rel_abund)) %>% 
  filter(tax_label %in% top10_ASVs_granules,
         rel_abund > 0.0099) %>% 
  ungroup() %>% 
  select(Phylum, Class, Order, Family, Genus, tax_label) %>% 
  distinct() %>% 
  write_csv("output_data/top10_ASVs_granules.csv")

# read functional group classifications
top10_ASVs_granules_classes = read.table("output_data/top10_ASVs_granules_classified.csv", header = T, sep = ";") %>% 
  as_tibble() %>% 
  dplyr::mutate(functional_group = factor(functional_group, levels = c("AOA", "AOB", "put_AOB", "NOB_Commamox", "MnOB", "put_MnOB", "others")))

# plot script
top_asv_rel_abund_granules <-
OBER_rare13092_table_granules_long_ASV %>% 
  #select(sampleID, ASV, rel_abund) %>%
  inner_join(., tax_beta_div %>% dplyr::rename(ASV = "taxon"), by = "ASV") %>% 
  dplyr::mutate(tax_label = paste0(Class, "__", Order, "__",Family, "__", Genus)) %>% 
  group_by(tax_label, date,filter_type, sampling_time, sampleID) %>% 
  summarise(rel_abund = sum(rel_abund)) %>% 
  filter(tax_label %in% top10_ASVs_granules,
         rel_abund > 0.0099) %>% 
  inner_join(., top10_ASVs_granules_classes %>% select(tax_label, tax_name, functional_group), by = "tax_label") %>% 
  dplyr::mutate(sampling_time = factor(sampling_time, levels = c("before_backwash","after_backwash"))) %>% 
  ggplot(aes(x=date, y=tax_name)) +
  scale_size_continuous(breaks = c(0.01, 0.05, 0.1, 0.2, 0.3),
                        labels = c("1%","5%","10%", "20%", "30%")) +
  scale_color_gradient(low = "dodgerblue", high = "darkblue") +
  facet_grid(cols = vars(filter_type, sampling_time), rows = vars(functional_group), scales = "free_y", space = "free_y") +
  geom_point(aes(size = rel_abund, alpha = rel_abund, color = rel_abund)) +
  theme_classic() +
  theme(axis.text.y = element_text(size = 8),
        legend.position = "bottom",
        panel.grid.major.y = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        strip.text.y = element_text(angle = 0))


top_asv_rel_abund_granules

# save plot
ggsave(plot = top_asv_rel_abund_granules, 
       file = stringr::str_glue("figures/{proj}_ASV_top10_rel_abund_granules.pdf"), 
       width = 10, 
       height = 7)

```

```{r plot top ASVs backwash, eval=T, echo=F, fig.height=3, fig.width=5, message=FALSE, warning=FALSE, cache=FALSE, include=T}

OBER_rare21227_table_backwash_long_ASV = 
OBER_rare21227_table_backwash %>% 
  as_tibble(rownames = "sampleID") %>% 
  rowwise() %>% dplyr::mutate(sample_sums = sum(c_across(2:ncol(.)))) %>% 
  mutate_at(vars(-sampleID, -sample_sums), funs(. / sample_sums)) %>%
  inner_join(., alpha2, by = "sampleID") %>% 
  select(sample_sums, colnames(alpha2), everything()) %>% 
  pivot_longer(cols = c(`32d66dbc09b2f1d42b219a2814d313c4`:ncol(.)), 
               names_to = "ASV", 
               values_to = "rel_abund")



psmelt_test = 
  psdata_OBER_beta_backwash %>% psmelt() %>% 
  select(OTU, Abundance, month) %>% 
  group_by(month) %>% 
  arrange(-Abundance, .by_group = T) %>% 
  slice_head(n = 10) %>% 
  ungroup() %>% pull(OTU) %>% unique 

psdata_OBER_beta_backwash %>% subset_taxa(., taxa_names(psdata_OBER_beta_backwash) %in% psmelt_test)


top10_ASVs_backwash = 
OBER_rare21227_table_backwash_long_ASV %>% 
  #select(sampleID, ASV, rel_abund) %>%
  inner_join(., tax_beta_div %>% dplyr::rename(ASV = "taxon"), by = "ASV") %>% 
  dplyr::mutate(tax_label = paste0(Class, "__", Order, "__",Family, "__", Genus)) %>% 
  group_by(tax_label, date,filter_type, sampling_time, sampleID) %>% 
  summarise(rel_abund = sum(rel_abund)) %>% 
  ungroup() %>% 
  group_by(sampleID) %>% 
  arrange(-rel_abund, .by_group = T) %>% 
  slice_head(n=10) %>% 
  pull(tax_label) %>% unique()

# plot script
top_asv_rel_abund_backwash <-
OBER_rare21227_table_backwash_long_ASV %>% 
  #select(sampleID, ASV, rel_abund) %>%
  inner_join(., tax_beta_div %>% dplyr::rename(ASV = "taxon"), by = "ASV") %>% 
  dplyr::mutate(tax_label = paste0(Class, "__", Order, "__",Family, "__", Genus)) %>% 
  group_by(tax_label, date,filter_type, sampling_time, sampleID) %>% 
  summarise(rel_abund = sum(rel_abund)) %>% 
  filter(tax_label %in% top10_ASVs_backwash,
         rel_abund > 0.0099) %>% 
  ggplot(aes(x=date, y=tax_label)) +
  geom_point(aes(size = rel_abund, alpha = rel_abund, color = rel_abund)) +
  scale_size_continuous(breaks = c(0.01, 0.05, 0.1, 0.2, 0.3),
                        labels = c("1%","5%","10%", "20%", "30%")) +
  scale_color_gradient(low = "dodgerblue", high = "darkblue") +
  facet_grid(cols = vars(filter_type, sampling_time)) +
  #theme_classic() #+
  theme(axis.text.y = element_text(size = 8),
        legend.position = "bottom",
        panel.grid.major.y = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank())


print(top_asv_rel_abund_backwash)

# save plot
ggsave(plot = top_asv_rel_abund_backwash, 
       file = stringr::str_glue("figures/{proj}_ASV_top10_rel_abund_backwash.pdf"), 
       width = 12, 
       height = 8)

```